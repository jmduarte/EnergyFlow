{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import energyflow as ef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_data import GraphDataset\n",
    "gdata = GraphDataset(root='/energyflowvol/datasets/', n_jets=200, n_events_merge=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DynamicEdgeNet, EdgeNet, DeeperDynamicEdgeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "big_dim = 32\n",
    "bigger_dim = 128\n",
    "global_dim = 2\n",
    "output_dim = 1\n",
    "fulllen = len(gdata)\n",
    "tv_frac = 0.10\n",
    "tv_num = math.ceil(fulllen*tv_frac)\n",
    "batch_size = 1\n",
    "lr = 0.001\n",
    "device = 'cuda:0'\n",
    "model_fname = 'DeeperDynamicEdgeNet'\n",
    "modpath = osp.join('/energyflowvol/models/',model_fname+'.best.pth')\n",
    "\n",
    "model = DeeperDynamicEdgeNet(input_dim=input_dim, big_dim=big_dim, bigger_dim=bigger_dim, \n",
    "                global_dim=global_dim, output_dim=output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, DataLoader, DataListLoader, Batch\n",
    "from torch.utils.data import random_split\n",
    "train_dataset, valid_dataset, test_dataset = random_split(gdata, [fulllen-2*tv_num,tv_num,tv_num])\n",
    "\n",
    "def collate(items): # collate function for data loaders (transforms list of lists to list)\n",
    "    l = sum(items, [])\n",
    "    return Batch.from_data_list(l)\n",
    "\n",
    "train_loader = DataListLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "train_loader.collate_fn = collate\n",
    "valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "valid_loader.collate_fn = collate\n",
    "test_loader = DataListLoader(test_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)\n",
    "test_loader.collate_fn = collate\n",
    "\n",
    "train_samples = len(train_dataset)\n",
    "valid_samples = len(valid_dataset)\n",
    "test_samples = len(test_dataset)\n",
    "\n",
    "print(train_samples)\n",
    "print(valid_samples)\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "@torch.no_grad()\n",
    "def test(model,loader,total,batch_size):\n",
    "    model.eval()\n",
    "    \n",
    "    mse = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    sum_loss = 0.\n",
    "    t = tqdm.tqdm(enumerate(loader),total=total/batch_size)\n",
    "    for i,data in t:\n",
    "        data = data.to(device)\n",
    "        batch_output = model(data)\n",
    "        batch_loss_item = mse(batch_output, data.y).item()\n",
    "        sum_loss += batch_loss_item\n",
    "        t.set_description(\"loss = %.5f\" % (batch_loss_item))\n",
    "        t.refresh() # to show immediately the update\n",
    "\n",
    "    return sum_loss/(i+1)\n",
    "\n",
    "def train(model, optimizer, loader, total, batch_size):\n",
    "    model.train()\n",
    "    \n",
    "    mse = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    sum_loss = 0.\n",
    "    t = tqdm.tqdm(enumerate(loader),total=total/batch_size)\n",
    "    for i,data in t:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(data)\n",
    "        batch_loss = mse(batch_output, data.y)\n",
    "        batch_loss.backward()\n",
    "        batch_loss_item = batch_loss.item()\n",
    "        t.set_description(\"loss = %.5f\" % batch_loss_item)\n",
    "        t.refresh() # to show immediately the update\n",
    "        sum_loss += batch_loss_item\n",
    "        optimizer.step()\n",
    "    \n",
    "    return sum_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 0.01999: 100%|██████████| 320/320.0 [02:10<00:00,  2.44it/s]\n",
      "loss = 0.59838: 100%|██████████| 40/40.0 [00:08<00:00,  4.90it/s]\n",
      "  0%|          | 0/320.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Training Loss:   0.1212\n",
      "               Validation Loss: 0.3224\n",
      "New best model saved to: /energyflowvol/models/DeeperDynamicEdgeNet.best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 0.05980: 100%|██████████| 320/320.0 [01:45<00:00,  3.04it/s]\n",
      "loss = 0.09364: 100%|██████████| 40/40.0 [00:04<00:00,  8.24it/s]\n",
      "  0%|          | 0/320.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Training Loss:   0.0657\n",
      "               Validation Loss: 0.0654\n",
      "New best model saved to: /energyflowvol/models/DeeperDynamicEdgeNet.best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss = 0.10278:  66%|██████▌   | 210/320.0 [01:09<00:36,  3.04it/s]"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "patience = 10\n",
    "stale_epochs = 0\n",
    "best_valid_loss = 99999\n",
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in range(0, n_epochs):\n",
    "    loss = train(model, optimizer, train_loader, train_samples, batch_size)\n",
    "    losses.append(loss)\n",
    "    valid_loss = test(model, valid_loader, valid_samples, batch_size)\n",
    "    val_losses.append(valid_loss)\n",
    "    print('Epoch: {:02d}, Training Loss:   {:.4f}'.format(epoch, loss))\n",
    "    print('               Validation Loss: {:.4f}'.format(valid_loss))\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        print('New best model saved to:',modpath)\n",
    "        torch.save(model.state_dict(),modpath)\n",
    "        stale_epochs = 0\n",
    "    else:\n",
    "        print('Stale epoch')\n",
    "        stale_epochs += 1\n",
    "    if stale_epochs >= patience:\n",
    "        print('Early stopping after %i stale epochs'%patience)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(modpath))\n",
    "ys = []\n",
    "preds = []\n",
    "diffs = []\n",
    "\n",
    "from graph_data import ONE_HUNDRED_GEV\n",
    "\n",
    "t = tqdm.tqdm(enumerate(test_loader),total=test_samples/batch_size)\n",
    "for i, data in t:\n",
    "    data.to(device)\n",
    "    ys.append(data.y.cpu().numpy().squeeze()*ONE_HUNDRED_GEV)\n",
    "    preds.append(model(data).cpu().detach().numpy().squeeze()*ONE_HUNDRED_GEV)\n",
    "    \n",
    "ys = np.concatenate(ys)   \n",
    "preds = np.concatenate(preds)   \n",
    "diffs = (preds-ys)\n",
    "rel_diffs = diffs[ys>0]/ys[ys>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "plt.plot(losses, marker='o',label='Training', alpha=0.5)\n",
    "plt.plot(val_losses, marker='o',label = 'Validation', alpha=0.5)\n",
    "plt.legend()\n",
    "ax.set_ylabel('Loss') \n",
    "ax.set_xlabel('Epoch') \n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_loss.pdf')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_loss.png')\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "plt.hist(ys, bins=np.linspace(0, 300, 101),label='True', alpha=0.5)\n",
    "plt.hist(preds, bins=np.linspace(0, 300, 101),label = 'Pred.', alpha=0.5)\n",
    "plt.legend()\n",
    "ax.set_xlabel('EMD [GeV]') \n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD.pdf')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD.png')\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "plt.hist(diffs, bins=np.linspace(-200, 200, 101))\n",
    "ax.set_xlabel('EMD diff. [GeV]')  \n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_diff.pdf')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_diff.png')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "plt.hist(rel_diffs, bins=np.linspace(-1, 1, 101))\n",
    "ax.set_xlabel('EMD rel. diff.')  \n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_rel_diff.pdf')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_rel_diff.png')\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "x_bins = np.linspace(0, 300, 101)\n",
    "y_bins = np.linspace(0, 300, 101)\n",
    "plt.hist2d(ys, preds, bins=[x_bins,y_bins])\n",
    "ax.set_xlabel('True EMD [GeV]')  \n",
    "ax.set_ylabel('Pred. EMD [GeV]')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_corr.pdf')\n",
    "fig.savefig('/energyflowvol/models/'+model_fname+'_EMD_corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
